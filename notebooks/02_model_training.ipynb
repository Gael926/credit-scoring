{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro_md",
            "metadata": {},
            "source": [
                "# 02. Entraînement et Sélection du Modèle Final\n",
                "\n",
                "Ce notebook implémente le workflow complet validé :\n",
                "1. **Entraînement Initial** : Comparer 4 modèles de base (Dummy, LogReg, RF, XGB) sur les datasets V1 et V2 pour choisir le meilleur dataset.\n",
                "2. **Sélection Dataset & Split** : On fixe le split (Train/Val/Test) du meilleur dataset identifié.\n",
                "3. **Optimisation LightGBM** : On optimise LightGBM uniquement sur ce dataset.\n",
                "4. **Cross-Validation & Construction Ensemble** : On entraîne 5 modèles via CV qui sont assemblés (Ensemble) pour une robustesse maximale, sans ré-entraînement global.\n",
                "5. **Evaluation Test & Sauvegarde** : On évalue cet Ensemble final sur le Test set (jamais vu)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "imports",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\aubin\\Majeur IA\\data analysis\\credit-scoring\\venv\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
                        "  return FileStore(store_uri, store_uri)\n",
                        "2025/12/13 20:28:11 INFO mlflow.tracking.fluent: Experiment with name 'Credit_Scoring_Final_Workflow' does not exist. Creating a new experiment.\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<Experiment: artifact_location=('file:///c:/Users/aubin/Majeur IA/data '\n",
                            " 'analysis/credit-scoring/notebooks/../mlruns/466018668070655282'), creation_time=1765654091893, experiment_id='466018668070655282', last_update_time=1765654091893, lifecycle_stage='active', name='Credit_Scoring_Final_Workflow', tags={}>"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import mlflow\n",
                "import sys\n",
                "import os\n",
                "import joblib\n",
                "import shutil\n",
                "\n",
                "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
                "if project_root not in sys.path: sys.path.append(project_root)\n",
                "\n",
                "from src.model_utils import (\n",
                "    get_train_val_test_split,\n",
                "    train_dummy, \n",
                "    train_random_forest, \n",
                "    train_xgboost, \n",
                "    train_lightgbm,\n",
                "    train_model_cv, \n",
                "    optimize_lightgbm,\n",
                "    evaluate_model, \n",
                "    find_best_threshold\n",
                ")\n",
                "\n",
                "mlflow.set_tracking_uri(\"../mlruns\")\n",
                "mlflow.set_experiment(\"Credit_Scoring_Final_Workflow\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "load_data",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Chargement V1/V2\n",
                "X_v1 = pd.read_pickle('../data/processed/X_prepared_v1.pkl')\n",
                "y_v1 = pd.read_pickle('../data/processed/y_prepared_v1.pkl')\n",
                "X_v2 = pd.read_pickle('../data/processed/X_prepared_v2.pkl')\n",
                "y_v2 = pd.read_pickle('../data/processed/y_prepared_v2.pkl')\n",
                "\n",
                "def clean_cols(df):\n",
                "    df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]\n",
                "    return df\n",
                "X_v1 = clean_cols(X_v1)\n",
                "X_v2 = clean_cols(X_v2)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bench_md",
            "metadata": {},
            "source": [
                "## 1. Entraînement initial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "run_bench",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Benchmarking Dataset v1\n",
                        "Entraînement Dummy_v1...\n",
                        "Meilleur seuil trouvé (Val): 0.01 (Coût: 37240)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:28:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
                        "2025/12/13 20:28:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Metrics (Test): {'auc': 0.5, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.9192663732737876, 'business_cost': np.int64(37240), 'val_best_cost': np.int64(37240)}\n",
                        "Entraînement RandomForest_v1...\n",
                        "Meilleur seuil trouvé (Val): 0.49 (Coût: 24679)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:28:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
                        "2025/12/13 20:28:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Metrics (Test): {'auc': 0.751841252998915, 'recall': 0.64312567132116, 'f1': 0.2729966944032828, 'accuracy': 0.7234591454029093, 'business_cost': np.int64(24717), 'val_best_cost': np.int64(24679)}\n",
                        "Entraînement XGBoost_v1...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:29:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Meilleur seuil trouvé (Val): 0.47 (Coût: 23317)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:29:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Metrics (Test): {'auc': 0.7811011886027459, 'recall': 0.6541353383458647, 'f1': 0.30628025397623687, 'accuracy': 0.7607691807401306, 'business_cost': np.int64(22627), 'val_best_cost': np.int64(23317)}\n",
                        "Entraînement LightGBM_v1...\n",
                        "[LightGBM] [Info] Number of positive: 17377, number of negative: 197880\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123890 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 20520\n",
                        "[LightGBM] [Info] Number of data points in the train set: 215257, number of used features: 275\n",
                        "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
                        "[LightGBM] [Info] Start training from score -0.000000\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "[50]\tvalid_0's binary_logloss: 0.581632\tvalid_0's business_cost: 24417\n",
                        "[100]\tvalid_0's binary_logloss: 0.559113\tvalid_0's business_cost: 23567\n",
                        "[150]\tvalid_0's binary_logloss: 0.547297\tvalid_0's business_cost: 23280\n",
                        "[200]\tvalid_0's binary_logloss: 0.538914\tvalid_0's business_cost: 23258\n",
                        "[250]\tvalid_0's binary_logloss: 0.531875\tvalid_0's business_cost: 23227\n",
                        "Early stopping, best iteration is:\n",
                        "[212]\tvalid_0's binary_logloss: 0.53717\tvalid_0's business_cost: 23192\n",
                        "Meilleur seuil trouvé (Val): 0.51 (Coût: 23141)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:29:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
                        "2025/12/13 20:30:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Metrics (Test): {'auc': 0.7818178650645198, 'recall': 0.685016111707841, 'f1': 0.29554538608584835, 'accuracy': 0.7363583150866088, 'business_cost': np.int64(22718), 'val_best_cost': np.int64(23141)}\n",
                        "Benchmarking Dataset v2\n",
                        "Entraînement Dummy_v2...\n",
                        "Meilleur seuil trouvé (Val): 0.01 (Coût: 37230)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:30:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
                        "2025/12/13 20:30:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Metrics (Test): {'auc': 0.5, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.9192663732737876, 'business_cost': np.int64(37240), 'val_best_cost': np.int64(37230)}\n",
                        "Entraînement RandomForest_v2...\n",
                        "Meilleur seuil trouvé (Val): 0.49 (Coût: 24370)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:30:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
                        "2025/12/13 20:30:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Metrics (Test): {'auc': 0.7544609364703311, 'recall': 0.6296992481203008, 'f1': 0.27576880108190743, 'accuracy': 0.7329763479090338, 'business_cost': np.int64(24728), 'val_best_cost': np.int64(24370)}\n",
                        "Entraînement XGBoost_v2...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:30:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Meilleur seuil trouvé (Val): 0.47 (Coût: 23192)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:30:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Metrics (Test): {'auc': 0.777869056571474, 'recall': 0.6514500537056928, 'f1': 0.2959980478282089, 'accuracy': 0.7498211459665706, 'business_cost': np.int64(23222), 'val_best_cost': np.int64(23192)}\n",
                        "Entraînement LightGBM_v2...\n",
                        "[LightGBM] [Info] Number of positive: 17377, number of negative: 197880\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085694 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 12549\n",
                        "[LightGBM] [Info] Number of data points in the train set: 215257, number of used features: 117\n",
                        "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
                        "[LightGBM] [Info] Start training from score -0.000000\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "[50]\tvalid_0's binary_logloss: 0.580694\tvalid_0's business_cost: 24346\n",
                        "[100]\tvalid_0's binary_logloss: 0.558407\tvalid_0's business_cost: 23624\n",
                        "[150]\tvalid_0's binary_logloss: 0.546756\tvalid_0's business_cost: 23311\n",
                        "[200]\tvalid_0's binary_logloss: 0.538804\tvalid_0's business_cost: 23135\n",
                        "Early stopping, best iteration is:\n",
                        "[183]\tvalid_0's binary_logloss: 0.541236\tvalid_0's business_cost: 23048\n",
                        "Meilleur seuil trouvé (Val): 0.50 (Coût: 23048)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:31:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
                        "2025/12/13 20:31:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Metrics (Test): {'auc': 0.7789777125237858, 'recall': 0.6855531686358755, 'f1': 0.28369818868763197, 'accuracy': 0.7205107637609209, 'business_cost': np.int64(23431), 'val_best_cost': np.int64(23048)}\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Data</th>\n",
                            "      <th>Model</th>\n",
                            "      <th>business_cost</th>\n",
                            "      <th>auc</th>\n",
                            "      <th>val_best_cost</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>v2</td>\n",
                            "      <td>LightGBM</td>\n",
                            "      <td>23431</td>\n",
                            "      <td>0.778978</td>\n",
                            "      <td>23048</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>v1</td>\n",
                            "      <td>LightGBM</td>\n",
                            "      <td>22718</td>\n",
                            "      <td>0.781818</td>\n",
                            "      <td>23141</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>v2</td>\n",
                            "      <td>XGB</td>\n",
                            "      <td>23222</td>\n",
                            "      <td>0.777869</td>\n",
                            "      <td>23192</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>v1</td>\n",
                            "      <td>XGB</td>\n",
                            "      <td>22627</td>\n",
                            "      <td>0.781101</td>\n",
                            "      <td>23317</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>v2</td>\n",
                            "      <td>RF</td>\n",
                            "      <td>24728</td>\n",
                            "      <td>0.754461</td>\n",
                            "      <td>24370</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>v1</td>\n",
                            "      <td>RF</td>\n",
                            "      <td>24717</td>\n",
                            "      <td>0.751841</td>\n",
                            "      <td>24679</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>v2</td>\n",
                            "      <td>Dummy</td>\n",
                            "      <td>37240</td>\n",
                            "      <td>0.500000</td>\n",
                            "      <td>37230</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>v1</td>\n",
                            "      <td>Dummy</td>\n",
                            "      <td>37240</td>\n",
                            "      <td>0.500000</td>\n",
                            "      <td>37240</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "  Data     Model  business_cost       auc  val_best_cost\n",
                            "7   v2  LightGBM          23431  0.778978          23048\n",
                            "3   v1  LightGBM          22718  0.781818          23141\n",
                            "6   v2       XGB          23222  0.777869          23192\n",
                            "2   v1       XGB          22627  0.781101          23317\n",
                            "5   v2        RF          24728  0.754461          24370\n",
                            "1   v1        RF          24717  0.751841          24679\n",
                            "4   v2     Dummy          37240  0.500000          37230\n",
                            "0   v1     Dummy          37240  0.500000          37240"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "results = []\n",
                "\n",
                "# On stocke les données splittées pour pouvoir réutiliser celles du gagnant\n",
                "splits = {}\n",
                "\n",
                "for name, X, y in [(\"v1\", X_v1, y_v1), (\"v2\", X_v2, y_v2)]:\n",
                "    print(f\"Benchmarking Dataset {name}\")\n",
                "    Xt, yt, Xv, yv, Xte, yte = get_train_val_test_split(X, y)\n",
                "    splits[name] = (Xt, yt, Xv, yv, Xte, yte)\n",
                "    \n",
                "    # Dummy\n",
                "    _, m = train_dummy(Xt, yt, Xv, yv, Xte, yte, name)\n",
                "    results.append({\"Data\": name, \"Model\": \"Dummy\", **m})\n",
                "    \n",
                "    # RF\n",
                "    _, m = train_random_forest(Xt, yt, Xv, yv, Xte, yte, name)\n",
                "    results.append({\"Data\": name, \"Model\": \"RF\", **m})\n",
                "    \n",
                "    # XGB\n",
                "    _, m = train_xgboost(Xt, yt, Xv, yv, Xte, yte, name)\n",
                "    results.append({\"Data\": name, \"Model\": \"XGB\", **m})\n",
                "    \n",
                "    # LightGBM (Baseline)\n",
                "    _, m = train_lightgbm(Xt, yt, Xv, yv, Xte, yte, name)\n",
                "    results.append({\"Data\": name, \"Model\": \"LightGBM\", **m})\n",
                "\n",
                "df_res = pd.DataFrame(results).sort_values(\"val_best_cost\")\n",
                "display(df_res[[\"Data\", \"Model\", \"business_cost\", \"auc\", \"val_best_cost\"]])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "select_ds_md",
            "metadata": {},
            "source": [
                "## 2. Sélection du Dataset Gagnant pour l'Optimisation\n",
                "On prend le dataset qui a donné le meilleur score LightGBM (le modèle cible)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "select_data",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset sélectionné pour optimisation LightGBM : v2\n",
                        "Shape Train: (215257, 124), Val: (46126, 124), Test: (46127, 124)\n"
                    ]
                }
            ],
            "source": [
                "lgbm_res = df_res[df_res[\"Model\"] == \"LightGBM\"].sort_values(\"val_best_cost\")\n",
                "best_data_name = lgbm_res.iloc[0][\"Data\"]\n",
                "print(f\"Dataset sélectionné pour optimisation LightGBM : {best_data_name}\")\n",
                "\n",
                "# Récupération des splits EXISTANTS\n",
                "X_train, y_train, X_val, y_val, X_test, y_test = splits[best_data_name]\n",
                "print(f\"Shape Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "optuna_md",
            "metadata": {},
            "source": [
                "## 3. Optimisation Optuna LightGBM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "run_optuna",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2025-12-13 20:31:26,714] A new study created in memory with name: no-name-203febb9-5cd4-4b8c-9432-5341587ebf5b\n",
                        "[I 2025-12-13 20:31:48,083] Trial 0 finished with value: 23212.0 and parameters: {'learning_rate': 0.14942003648617996, 'num_leaves': 167, 'max_depth': 8, 'min_child_samples': 81, 'min_split_gain': 0.16459778279698467, 'reg_alpha': 16.13110834403555, 'reg_lambda': 24.15329235983281}. Best is trial 0 with value: 23212.0.\n",
                        "[I 2025-12-13 20:32:06,316] Trial 1 finished with value: 23098.0 and parameters: {'learning_rate': 0.24156006546723113, 'num_leaves': 81, 'max_depth': 6, 'min_child_samples': 13, 'min_split_gain': 0.4180430648173412, 'reg_alpha': 21.21827513812108, 'reg_lambda': 20.26443030298551}. Best is trial 1 with value: 23098.0.\n",
                        "[I 2025-12-13 20:32:21,391] Trial 2 finished with value: 23286.0 and parameters: {'learning_rate': 0.23594889097981117, 'num_leaves': 45, 'max_depth': 11, 'min_child_samples': 81, 'min_split_gain': 0.6231616444495178, 'reg_alpha': 28.786322998578733, 'reg_lambda': 21.30810021972022}. Best is trial 1 with value: 23098.0.\n",
                        "[I 2025-12-13 20:34:28,487] Trial 3 finished with value: 23188.0 and parameters: {'learning_rate': 0.011522479962692997, 'num_leaves': 128, 'max_depth': 6, 'min_child_samples': 81, 'min_split_gain': 0.16920198987187118, 'reg_alpha': 12.208021757493887, 'reg_lambda': 13.101252408666985}. Best is trial 1 with value: 23098.0.\n",
                        "[I 2025-12-13 20:35:47,786] Trial 4 finished with value: 22811.0 and parameters: {'learning_rate': 0.042259918925449495, 'num_leaves': 47, 'max_depth': 8, 'min_child_samples': 97, 'min_split_gain': 0.5002888403429622, 'reg_alpha': 4.299254375267902, 'reg_lambda': 14.348012168303342}. Best is trial 4 with value: 22811.0.\n",
                        "[I 2025-12-13 20:36:22,440] Trial 5 finished with value: 23022.0 and parameters: {'learning_rate': 0.10141193370796471, 'num_leaves': 81, 'max_depth': 11, 'min_child_samples': 80, 'min_split_gain': 0.7279111852902278, 'reg_alpha': 38.90164828588255, 'reg_lambda': 40.99417436642908}. Best is trial 4 with value: 22811.0.\n",
                        "[I 2025-12-13 20:36:59,880] Trial 6 finished with value: 22941.0 and parameters: {'learning_rate': 0.06748688612296004, 'num_leaves': 204, 'max_depth': 14, 'min_child_samples': 21, 'min_split_gain': 0.13178402950567136, 'reg_alpha': 45.808679127157525, 'reg_lambda': 24.42577717329797}. Best is trial 4 with value: 22811.0.\n",
                        "[I 2025-12-13 20:38:04,258] Trial 7 finished with value: 23011.0 and parameters: {'learning_rate': 0.02315603720572506, 'num_leaves': 97, 'max_depth': 10, 'min_child_samples': 74, 'min_split_gain': 0.3747984092482459, 'reg_alpha': 45.77260153650118, 'reg_lambda': 17.190668113969277}. Best is trial 4 with value: 22811.0.\n",
                        "[I 2025-12-13 20:38:30,783] Trial 8 finished with value: 23025.0 and parameters: {'learning_rate': 0.1937492916843634, 'num_leaves': 85, 'max_depth': 6, 'min_child_samples': 36, 'min_split_gain': 0.6086918045801044, 'reg_alpha': 48.52747247604978, 'reg_lambda': 48.00933463676571}. Best is trial 4 with value: 22811.0.\n",
                        "[I 2025-12-13 20:39:02,151] Trial 9 finished with value: 22879.0 and parameters: {'learning_rate': 0.19047043494686897, 'num_leaves': 202, 'max_depth': 4, 'min_child_samples': 25, 'min_split_gain': 0.6110927234476315, 'reg_alpha': 11.010811056471697, 'reg_lambda': 21.90946531273307}. Best is trial 4 with value: 22811.0.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Meilleurs params: {'learning_rate': 0.042259918925449495, 'num_leaves': 47, 'max_depth': 8, 'min_child_samples': 97, 'min_split_gain': 0.5002888403429622, 'reg_alpha': 4.299254375267902, 'reg_lambda': 14.348012168303342}\n"
                    ]
                }
            ],
            "source": [
                "best_params = optimize_lightgbm(X_train, y_train, X_val, y_val, n_trials=10)\n",
                "\n",
                "final_params = best_params.copy()\n",
                "final_params.update({\n",
                "    \"metric\": \"custom\", \"objective\": \"binary\", \"verbosity\": -1,\n",
                "    \"boosting_type\": \"gbdt\", \"random_state\": 42, \"n_jobs\": -1,\n",
                "    \"class_weight\": \"balanced\", \"n_estimators\": 1000\n",
                "})"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cv_ensemble_md",
            "metadata": {},
            "source": [
                "## 4. Cross-Validation & Construction de l'Ensemble Final\n",
                "On entraîne 5 modèles fold par CV. L'Ensemble final est la moyenne de ces 5 modèles (stockée dans une classe simplifiée)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "run_cv_final",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:39:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fold 1 terminé (best_iteration=264).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:40:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fold 2 terminé (best_iteration=326).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:41:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fold 3 terminé (best_iteration=293).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:42:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fold 4 terminé (best_iteration=320).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:43:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fold 5 terminé (best_iteration=197).\n",
                        "\n",
                        "Calibration seuil Ensemble sur X_val...\n",
                        "Metrics Test (Ensemble): {'auc': 0.7817818505991547, 'recall': 0.6769602577873255, 'f1': 0.29055494727136516, 'accuracy': 0.7331064235697097, 'business_cost': np.int64(23138)}\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:43:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "METRICS FINALES SUR TEST (Ensemble CV): {'auc': 0.7817818505991547, 'recall': 0.6769602577873255, 'f1': 0.29055494727136516, 'accuracy': 0.7331064235697097, 'business_cost': np.int64(23138)}\n"
                    ]
                }
            ],
            "source": [
                "# Appel à notre fonction CV simplifiée qui retourne l'Ensemble et ses metrics Test\n",
                "\n",
                "ensemble_final, metrics_final = train_model_cv(\n",
                "    X_train, y_train, X_val, y_val, X_test, y_test, \n",
                "    dataset_name=f\"{best_data_name}_Ensemble_Final\", \n",
                "    params=final_params\n",
                ")\n",
                "\n",
                "print(\"METRICS FINALES SUR TEST (Ensemble CV):\", metrics_final)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Entraînement du modèle final sans CV car le notebook 3 ne fonctionne pas avec l'ensemble de modèles du CV"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Entraînement LightGBM_v2_Ensemble_Final...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "[50]\tvalid_0's business_cost: 24478\n",
                        "[100]\tvalid_0's business_cost: 23865\n",
                        "[150]\tvalid_0's business_cost: 23313\n",
                        "[200]\tvalid_0's business_cost: 23127\n",
                        "[250]\tvalid_0's business_cost: 22999\n",
                        "[300]\tvalid_0's business_cost: 22920\n",
                        "[350]\tvalid_0's business_cost: 22874\n",
                        "[400]\tvalid_0's business_cost: 22811\n",
                        "[450]\tvalid_0's business_cost: 22931\n",
                        "Early stopping, best iteration is:\n",
                        "[400]\tvalid_0's business_cost: 22811\n",
                        "Meilleur seuil trouvé (Val): 0.50 (Coût: 22811)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025/12/13 20:44:38 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
                        "2025/12/13 20:44:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Metrics (Test): {'auc': 0.7814696260192563, 'recall': 0.6616541353383458, 'f1': 0.2956563474922006, 'accuracy': 0.7454852906107052, 'business_cost': np.int64(23080), 'val_best_cost': np.int64(22811)}\n"
                    ]
                }
            ],
            "source": [
                "#on repasse au meilleur modele avec meilleur parametre sans CV car ne fonctionne pas\n",
                "modele_final, metrics_final = train_lightgbm(\n",
                "    X_train, y_train, X_val, y_val, X_test, y_test, \n",
                "    dataset_name=f\"{best_data_name}_Ensemble_Final\", \n",
                "    params=final_params\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "save_md",
            "metadata": {},
            "source": [
                "## 6. Sauvegarde"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "save_disk",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Modèle Ensemble sauvegardé et prêt pour Docker!\n"
                    ]
                }
            ],
            "source": [
                "if not os.path.exists(\"../models\"):\n",
                "    os.makedirs(\"../models\")\n",
                "\n",
                "joblib.dump(modele_final, \"../models/best_model.pkl\")\n",
                "\n",
                "path_serving = \"../models/final_model\"\n",
                "if os.path.exists(path_serving): shutil.rmtree(path_serving)\n",
                "# Sauvegarde MLflow comme modèle sklearn\n",
                "mlflow.sklearn.save_model(modele_final, path_serving)\n",
                "print(\"Modèle Ensemble sauvegardé et prêt pour Docker!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
